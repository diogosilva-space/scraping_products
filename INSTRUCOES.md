# üìã INSTRU√á√ïES DE USO - Sistema de Scraping de Produtos

## üöÄ Primeiros Passos

### 1. Instala√ß√£o das Depend√™ncias

```bash
# Instale todas as depend√™ncias
npm install

# Instale o navegador Chrome para o Puppeteer
npx puppeteer browsers install chrome
```

### 2. Configura√ß√£o do Ambiente

```bash
# Copie o arquivo de exemplo de vari√°veis de ambiente
cp env.example .env

# Edite o arquivo .env com suas configura√ß√µes
nano .env
```

**Exemplo de configura√ß√£o no .env:**
```env
# Configura√ß√µes gerais
HEADLESS=true
DELAY_BETWEEN_REQUESTS=1000
MAX_RETRIES=3

# Credenciais (se necess√°rio)
SPOTGIFTS_EMAIL=seu-email@exemplo.com
SPOTGIFTS_PASSWORD=sua-senha
XBZBRINDES_EMAIL=seu-email@exemplo.com
XBZBRINDES_PASSWORD=sua-senha
```

## üß™ Testando o Sistema

### Teste B√°sico
```bash
# Executa todos os testes
npm test

# Teste espec√≠fico
npm run test:basic
npm run test:config
npm run test:utils
```

### Teste de Navegador
```bash
# Testa se o Puppeteer est√° funcionando
node src/test/test-scraper.js
```

## üîç Analisando Sites

### An√°lise Autom√°tica
```bash
# Analisa todos os sites configurados
npm run analyze

# An√°lise espec√≠fica
npm run analyze:spotgifts
npm run analyze:xbzbrindes

# An√°lise manual
node src/analyze-sites.js --site spotgifts
```

**O que a an√°lise faz:**
- Identifica seletores CSS para produtos
- Analisa estrutura da p√°gina
- Gera recomenda√ß√µes de configura√ß√£o
- Salva relat√≥rio detalhado na pasta `analysis/`

## üöÄ Executando o Scraping

### Scraping de Todos os Sites
```bash
# Executa scraping de todos os sites
npm start

# Ou diretamente
node src/index.js
```

### Scraping de Site Espec√≠fico
```bash
# Spot Gifts
npm run scrape:spotgifts

# XBZ Brindes
npm run scrape:xbzbrindes

# Comando personalizado
node src/index.js --site "Spot Gifts"
```

### Op√ß√µes de Linha de Comando
```bash
# Lista sites dispon√≠veis
node src/index.js --list

# Executa site espec√≠fico
node src/index.js --site "nome-do-site"

# Exibe ajuda
node src/index.js --help
```

## üìä Estrutura de Sa√≠da

### Arquivos Gerados
```
output/
‚îú‚îÄ‚îÄ spot_gifts_2024-01-15T10-30-00.json    # Dados dos produtos
‚îú‚îÄ‚îÄ spot_gifts_stats_2024-01-15T10-30-00.json  # Estat√≠sticas
‚îú‚îÄ‚îÄ spot_gifts_2024-01-15T10-30-00.csv     # Exporta√ß√£o CSV
‚îî‚îÄ‚îÄ spot_gifts_resumo_2024-01-15T10-30-00.txt  # Relat√≥rio de resumo
```

### Estrutura dos Dados
```json
{
  "metadata": {
    "site": "Spot Gifts",
    "total_produtos": 1246,
    "data_extracao": "2024-01-15T10:30:00.000Z",
    "versao": "1.0.0"
  },
  "produtos": [
    {
      "referencia": "94690",
      "nome": "GILDED. Squeeze dobr√°vel em PE",
      "descricao": "Squeeze dobr√°vel em PE com bico de sistema push-pull",
      "cores": ["Preto", "Azul", "Vermelho"],
      "imagens": ["https://exemplo.com/imagem1.jpg"],
      "categorias": ["Squeezes & Copos"],
      "informacoes_adicionais": "460 mL",
      "preco": null,
      "url_produto": "https://exemplo.com/produto/94690",
      "data_extracao": "2024-01-15T10:30:00.000Z",
      "site_origem": "Spot Gifts"
    }
  ]
}
```

## ‚öôÔ∏è Personalizando Configura√ß√µes

### 1. Configura√ß√£o de Identifica√ß√£o

**IMPORTANTE**: Cada site deve ter um prefixo √∫nico para suas refer√™ncias:

```javascript
// src/config/spotgifts.js
identification: {
  referencePrefix: 'SP-',    // Refer√™ncias: SP-94690, SP-94689, etc.
  siteCode: 'SPOT'
}

// src/config/xbzbrindes.js  
identification: {
  referencePrefix: 'XB-',    // Refer√™ncias: XB-12345, XB-67890, etc.
  siteCode: 'XBZ'
}
```

**Benef√≠cios:**
- ‚úÖ Evita conflitos entre refer√™ncias de diferentes sites
- ‚úÖ Facilita identifica√ß√£o da origem do produto
- ‚úÖ Permite consultas espec√≠ficas por site
- ‚úÖ Mant√©m hist√≥rico de produtos organizado

### 2. Ajustando Seletores

Edite os arquivos em `src/config/`:

```javascript
// src/config/spotgifts.js
selectors: {
  productCard: '.novo-seletor-produto',  // Ajuste conforme necess√°rio
  productLinks: 'a[href*="/novo-padrao"]',
  // ... outros seletores
}
```

### 2. Ajustando Delays

```javascript
// Configura√ß√µes de rolagem
scroll: {
  delay: 2000,        // Aumente se o site for lento
  maxScrolls: 150,    // Ajuste conforme n√∫mero de produtos
  scrollStep: 1000,   // Pixels por rolagem
  waitForNewContent: 3000  // Tempo para aguardar carregamento
}

// Configura√ß√µes de extra√ß√£o
extraction: {
  delayBetweenProducts: 2000,  // Delay entre produtos
  maxRetries: 5,               // Tentativas em caso de erro
  timeout: 45000               // Timeout para opera√ß√µes
}
```

### 3. Adicionando Novo Site

1. **Crie arquivo de configura√ß√£o:**
```bash
cp config-example.js src/config/novo-site.js
```

2. **Edite a configura√ß√£o:**
```javascript
module.exports = {
  name: 'Novo Site',
  baseUrl: 'https://www.novosite.com',
  catalogUrl: 'https://www.novosite.com/catalogo/',
  
  // Configura√ß√£o de identifica√ß√£o (IMPORTANTE!)
  identification: {
    referencePrefix: 'NS-',    // Prefixo para refer√™ncias (ex: NS-12345)
    siteCode: 'NOVOSITE'       // C√≥digo √∫nico do site
  },
  
  // ... configure seletores e outras op√ß√µes
};
```

3. **Crie o scraper:**
```bash
cp src/scrapers/spotgifts.js src/scrapers/novo-site.js
```

4. **Edite o scraper:**
```javascript
const config = require('../config/novo-site');

class NovoSiteScraper extends BaseScraper {
  constructor() {
    super(config);
  }
  // ... implementa√ß√µes espec√≠ficas
}
```

5. **Adicione ao sistema principal:**
```javascript
// src/index.js
const NovoSiteScraper = require('./scrapers/novo-site');

this.scrapers = [
  // ... outros scrapers
  { name: 'Novo Site', scraper: NovoSiteScraper }
];
```

6. **Adicione scripts no package.json:**
```json
{
  "scripts": {
    "scrape:novo-site": "node src/scrapers/novo-site.js"
  }
}
```

## üîß Solu√ß√£o de Problemas

### Problemas Comuns

#### 1. Navegador n√£o inicia
```bash
# Reinstale o Puppeteer
npm uninstall puppeteer
npm install puppeteer

# Instale o Chrome manualmente
npx puppeteer browsers install chrome
```

#### 2. Seletores n√£o encontrados
```bash
# Analise o site primeiro
npm run analyze:spotgifts

# Verifique o relat√≥rio na pasta analysis/
# Ajuste os seletores conforme as recomenda√ß√µes
```

#### 3. Timeout de opera√ß√µes
```javascript
// Aumente os timeouts na configura√ß√£o
extraction: {
  timeout: 60000,  // 60 segundos
  delayBetweenProducts: 2000
}
```

#### 4. Produtos n√£o carregam
```javascript
// Ajuste configura√ß√µes de rolagem
scroll: {
  delay: 3000,           // Mais tempo entre rolagens
  waitForNewContent: 5000, // Mais tempo para carregar
  maxScrolls: 200        // Mais tentativas
}
```

### Logs e Debug

#### Habilitar Debug
```env
# .env
DEBUG=true
LOG_LEVEL=debug
```

#### Verificar Logs
```bash
# Logs em tempo real
tail -f logs/scraping.log

# √öltimas linhas
tail -n 100 logs/scraping.log
```

## üìà Monitoramento e Performance

### M√©tricas Importantes
- **Taxa de sucesso**: Produtos v√°lidos vs. total
- **Tempo de execu√ß√£o**: Por site e total
- **Erros**: Tipos e frequ√™ncia
- **Produtos por minuto**: Velocidade de extra√ß√£o

### Otimiza√ß√µes
```javascript
// Configura√ß√µes de performance
performance: {
  disableImages: true,     // Mais r√°pido
  disableCSS: true,        // Mais r√°pido
  disableFonts: true,      // Mais r√°pido
  maxConcurrentRequests: 1 // Evita sobrecarga
}
```

## üõ°Ô∏è Considera√ß√µes de Seguran√ßa

### Boas Pr√°ticas
- ‚úÖ Use delays apropriados entre requisi√ß√µes
- ‚úÖ Respeite robots.txt dos sites
- ‚úÖ N√£o sobrecarregue servidores
- ‚úÖ Use user-agent realista
- ‚úÖ Considere usar APIs oficiais quando dispon√≠veis

### Evite
- ‚ùå Muitas requisi√ß√µes simult√¢neas
- ‚ùå Delays muito baixos
- ‚ùå Ignorar termos de uso
- ‚ùå Scraping em hor√°rios de pico

## üìû Suporte e Manuten√ß√£o

### Verifica√ß√µes Regulares
1. **Teste mensal** com `npm test`
2. **An√°lise de sites** com `npm run analyze`
3. **Verifica√ß√£o de logs** para erros
4. **Atualiza√ß√£o de seletores** se necess√°rio

### Backup de Configura√ß√µes
```bash
# Fa√ßa backup das configura√ß√µes
cp -r src/config/ backup-config-$(date +%Y%m%d)

# Restaure se necess√°rio
cp -r backup-config-20240115/ src/config/
```

## üéØ Pr√≥ximos Passos

### Melhorias Sugeridas
1. **Interface web** para monitoramento
2. **Agendamento** de execu√ß√µes autom√°ticas
3. **Notifica√ß√µes** por email/telegram
4. **Dashboard** com m√©tricas em tempo real
5. **Integra√ß√£o** com bancos de dados
6. **API REST** para consultas

### Recursos Avan√ßados
- **Proxy rotation** para evitar bloqueios
- **Captcha solving** autom√°tico
- **Machine learning** para seletores
- **Distributed scraping** em m√∫ltiplas m√°quinas

---

**üéâ Parab√©ns! Voc√™ est√° pronto para usar o sistema de scraping!**

Para d√∫vidas ou problemas, verifique:
1. Os logs em `logs/scraping.log`
2. A documenta√ß√£o no `README.md`
3. Os exemplos em `config-example.js`
4. Os testes em `src/test/`
