# Sistema de Scraping de Produtos

Sistema automatizado para extraÃ§Ã£o de dados de produtos de sites de e-commerce usando Puppeteer.

## ğŸš€ Funcionalidades

- Scraping automÃ¡tico de produtos com rolagem infinita
- Suporte a mÃºltiplos sites com configuraÃ§Ãµes personalizadas
- ExtraÃ§Ã£o de dados estruturados (referÃªncia, nome, descriÃ§Ã£o, cores, imagens, etc.)
- Sistema de configuraÃ§Ã£o modular por site
- Suporte a login quando necessÃ¡rio
- Salvamento de dados em formato JSON
- Interface de linha de comando com progresso visual

## ğŸ“‹ Sites Suportados

- [Spot Gifts](https://www.spotgifts.com.br/pt/catalogo/) - CatÃ¡logo de brindes corporativos
- [XBZ Brindes](https://www.xbzbrindes.com.br/) - Brindes personalizados

## ğŸ› ï¸ InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone <seu-repositorio>
cd scraping-products

# Instale as dependÃªncias
npm install

# Instale o Puppeteer (pode demorar na primeira vez)
npx puppeteer browsers install chrome
```

### ğŸ”„ Atualizando DependÃªncias

Se vocÃª encontrar avisos de versÃµes desatualizadas:

```bash
# Execute o script de atualizaÃ§Ã£o automÃ¡tica
chmod +x update-dependencies.sh
./update-dependencies.sh

# Ou atualize manualmente
npm update
npx puppeteer browsers install chrome
```

## âš™ï¸ ConfiguraÃ§Ã£o

### 1. VariÃ¡veis de Ambiente

Crie um arquivo `.env` na raiz do projeto:

```env
# ConfiguraÃ§Ãµes gerais
HEADLESS=true
DELAY_BETWEEN_REQUESTS=1000
MAX_RETRIES=3

# Credenciais de login (quando necessÃ¡rio)
SPOTGIFTS_EMAIL=seu-email@exemplo.com
SPOTGIFTS_PASSWORD=sua-senha
XBZBRINDES_EMAIL=seu-email@exemplo.com
XBZBRINDES_PASSWORD=sua-senha
```

### 2. ConfiguraÃ§Ã£o dos Sites

Cada site tem seu arquivo de configuraÃ§Ã£o em `src/config/` com:
- URLs base
- Seletores CSS/XPath
- ConfiguraÃ§Ãµes de rolagem
- Mapeamento de campos

## ğŸš€ Uso

### Scraping de um site especÃ­fico:

```bash
# Scraping do Spot Gifts
npm run scrape:spotgifts

# Scraping do XBZ Brindes
npm run scrape:xbzbrindes
```

### Scraping de todos os sites:

```bash
npm start
```

## ğŸ“Š Estrutura dos Dados

Cada produto extraÃ­do contÃ©m:

```json
{
  "referencia": "string (obrigatÃ³rio)",
  "nome": "string (obrigatÃ³rio)",
  "descricao": "string (obrigatÃ³rio)",
  "cores": ["array de strings (obrigatÃ³rio)"],
  "imagens": ["array de URLs (obrigatÃ³rio)"],
  "categorias": ["array de strings (opcional)"],
  "informacoes_adicionais": "string (opcional)",
  "preco": "number (opcional)",
  "url_produto": "string",
  "data_extracao": "ISO string"
}
```

## ğŸ“ Estrutura do Projeto

```
src/
â”œâ”€â”€ config/           # ConfiguraÃ§Ãµes dos sites
â”œâ”€â”€ scrapers/         # ImplementaÃ§Ãµes dos scrapers
â”œâ”€â”€ utils/            # UtilitÃ¡rios compartilhados
â”œâ”€â”€ models/           # Modelos de dados
â””â”€â”€ index.js          # Arquivo principal
```

## ğŸ”§ PersonalizaÃ§Ã£o

Para adicionar um novo site:

1. Crie um arquivo de configuraÃ§Ã£o em `src/config/`
2. Implemente o scraper em `src/scrapers/`
3. Adicione o script no `package.json`
4. Configure as variÃ¡veis de ambiente se necessÃ¡rio

## âš ï¸ ConsideraÃ§Ãµes Legais

- Respeite os termos de uso dos sites
- Use delays apropriados entre requisiÃ§Ãµes
- NÃ£o sobrecarregue os servidores
- Considere usar APIs oficiais quando disponÃ­veis

## ğŸ“ Logs

O sistema gera logs detalhados em:
- Console com cores
- Arquivo `logs/scraping.log`
- RelatÃ³rios de progresso em tempo real

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch para sua feature
3. Commit suas mudanÃ§as
4. Push para a branch
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

MIT License - veja o arquivo LICENSE para detalhes.
